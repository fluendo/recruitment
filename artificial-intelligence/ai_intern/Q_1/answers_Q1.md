Applicant: Javier Rodríguez Calderón

**What do you think it occurred during this model development (trainning & evaluation)?**

Es muy probable que el modelo sufriera overfitting durante el entrenamiento. Es decir, el modelo haya aprendido sobre una base de datos tan concreta que realmente ha “memorizado” y no es capaz de generalizar. Esto puede ocurrir porque las imágenes usadas tenían siempre las mismas condiciones: tamaño constante, iluminación uniforme, tipografía de las letras igual (lo cual es razonable en matrículas de un mismo país), ángulo fijo entre la cámara y la matrícula… Estas condiciones hacen que el modelo aprenda a reconocer muy bien esas situaciones, pero que luego no generalice bien a escenarios diferentes.  
Otra posible causa es que el conjunto de datos fuera demasiado pequeño y no se aplicaran técnicas adecuadas de preprocesamiento o aumento de datos (data augmentation). Con un dataset limitado, el modelo no puede aprender la variedad de casos que encontrará, lo que afecta a su capacidad para generalizar.  
Otro posible error aunque más trivial son la calidad de las imágenes utilizadas para el entrenamiento. Si las imágenes eran borrosas, con ruido o mala iluminación dificulta que el modelo aprenda correctamente las características relevantes.  
Durante el entrenamiento, por último se me ocurre que hubieran problemas en la gestión de los datos de entrenamiento como **clasificación incorrecta de las imágenes** o un mal uso de técnicas como k-folds. Pueden hacer que el modelo se entrene con datos mal etiquetados o que la evaluación no refleje correctamente su rendimiento real.  
Durante la evaluación, puede ser que no se atendieran suficiente atención a los falsos positivos. En este caso, estos serían cuando el modelo predice una matrícula que no coincide exactamente con la real, pero esta diferencia no se penaliza adecuadamente. Para detectar esto, sería útil analizar la matriz de confusión, para que se pueda ajustar el sistema para minimizar estas falsas alarmas.

**How would you fix this behavior? Please provide at least 2 options explaining their pros and drawbacks.**

La primera opción que se me ocurre sería el recopilar un dataset más diverso. Sería crucial que hubieran diferentes matrículas y para afinarlo más que, por ejemplo, se distinguiesen solo por una letra. Así el modelo saldría mucho más robusto pues aprendería delante de casos confusos como el que se encontraba cuando se equivocó. El inconveniente sería lo difícil y costoso que sería tener este dataset. Esto conllevaría también tiempos de entrenamiento más largos. Además, nunca se sabe con certeza cuándo el conjunto es lo suficientemente grande y variado.  
Como alternativa para no tener que conseguir un dataset más grande y equilibrado podríamos aplicar técnicas de aumento de datos usando librerías disponibles como Albumentation para simular posibles variaciones. Aunque no es tan bueno como datos reales, seguro ayuda a mejorar la generalización del modelo.  
Otra opción sería modificar la función de pérdida sobre la cual el modelo aprende durante el entrenamiento para penalizar más los falsos positivos (cuando el modelo detecta una matrícula incorrecta). Esto hará que el modelo disminuya los errores graves como confundir una placa con otra muy similar. El inconveniente principal para implementar esta solución es que es necesario definir bien qué casos son falsos positivos y controlar que la salida del modelo tenga sentido (tenga por ejemplo 7 caracteres).  Además, puede requerir un análisis previo (con matriz de confusión, por ejemplo) para conocer bien el tipo de error que se quiere penalizar, y no siempre es trivial.  
Por último, otra forma de reducir errores sería comprobar automáticamente si la matrícula detectada corresponde realmente al vehículo predicho usando bases de datos oficiales (por ejemplo, la base de datos de matriculación de la DGT en nuestro país). Esto no requiere Deep Learning (si bien se puede agilizar con ello), sino simplemente un sistema de validación cruzada de los datos. Lo positivo es que añade una capa extra de seguridad para filtrar errores del modelo. El punto débil es que esta solución depende de disponer de una base de datos actualizada.

**What do you think it will occur when running this AI in a different country with different plates formats? How would you ensure system accuracy?**

Nuevamente, el problema principal sería el dataset para el entrenamiento. Si queremos extrapolar directamente el modelo en uso a otro país, este modelo estaría ajustado a unos datos específicos de matrículas de ese país. El tipo de letra, el color de las letras y del fondo o los caracteres cambiarían de un lugar a otro.  
Respecto a este problema, podríamos hacer uso del modelo original que ya ha aprendido características general (forma rectangular, por ejemplo) y a continuación añadir nuevas capas para adaptar el modelo a cada país. De esta manera, los pesos de las capas no parten de cero facilitando así el aprendizaje y haciendo que sea más rápido la adaptación a las nuevas características. Esta estrategia la empleé en mi TFG y resultó muy útil para trasladar de un entrenamiento a otro lo “aprendido”. En la última pregunta lo desarrollo más.  
Otra opción algo más compleja sería entrenar un modelo completamente nuevo, desde cero, para cada país. Esto implicaría tener un dataset propio adaptado a cada modelo de matrículas. A largo plazo puede ser más precisa pero requiere un esfuerzo de recopilación y entrenamiento.

**Do you know any OCR (Optical Character Recognition) algorithms (Deep learning based) that could be used here?**

Honestamente, desconozco algoritmos OCR que se podrían utilizar en este caso concreto. Solo conozco brevemente de forma teórica la CRNN que hace uso de las redes convolucionales CNN para procesar texto pero nunca la he implementado así que no puedo afirmar que funcionaría al 100 % en un caso como este. En profundidad he trabajado con U-Net que son útiles para labores de segmentación. Se que me ocurre una posible implementación de mejora que consistiría en primero segmentar la matrícula para después ya aplicar un algoritmo OCR como se hace. Esto ayudaría por ejemplo en los casos en los que se quiera aplicar esta IA en un país diferente, al tener matrículas de formas diferentes. Aunque no es OCR, comparte muchas de las bases técnicas y ya comportaría una mejora.

**Explain a Computer Vision / Artificial Intelligence project in which you have participated (goals, your role, difficulties you found, how they were solved, …)**

Durante mi Erasmus, estoy realizando mi Trabajo de Fin de Grado en un proyecto de Deep    Learning desarrollado en colaboración con una clínica de fertilización in vitro en Praga. El objetivo principal es analizar automáticamente imágenes microscópicas de ovocitos humanos para detectar estructuras clave como el citoplasma, el cuerpo polar y el huso meiótico, y calcular el ángulo formado entre ellas. Este ángulo se considera un posible indicador del grado de madurez del ovocito, un factor importante para aumentar las probabilidades de éxito en tratamientos de fertilización.  
He sido responsable de todo el pipeline del proyecto, desde la preparación y el preprocesamiento de los datos hasta el diseño, entrenamiento y validación de los diferentes modelos. Utilicé un modelo U-Net para segmentar el citoplasma en más de 17.000 imágenes, logrando métricas altas de precisión. Para localizar el centro del citoplasma y del cuerpo polar, cambié la estrategia inicial de regresión directa de coordenadas a mapas de calor gaussianos, lo que mejoró la robustez ante imágenes con ruido o estructuras ausentes (no siempre el huso meiótico se encuentra). Además, implementé una función de pérdida personalizada para manejar correctamente los casos en que ciertas estructuras no aparecían.  
Dado que el dataset específico de ovocitos humanos era pequeño (apenas 130 imágenes), utilicé preentrenamiento y transferencia de aprendizaje con datasets relacionados para mejorar el rendimiento del modelo. Finalmente, calculamos el ángulo clínico relevante usando la fórmula del coseno con las coordenadas estimadas.  
Entre las principales dificultades estuvieron el tamaño reducido del dataset, la presencia de imágenes poco claras y la necesidad de que el modelo generalizara bien. Para ello, apliqué técnicas de aumento de datos con Albumentations y ajusté el modelo para evitar sobreajuste.  
Los resultados han sido muy prometedores, mostrando mejoras significativas en la localización de las estructuras, especialmente del huso meiótico. El proyecto continuará con el objetivo de apoyar la selección de ovocitos maduros en clínicas de fertilización.  
